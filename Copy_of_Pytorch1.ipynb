{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What is a Abstraction?"
      ],
      "metadata": {
        "id": "N05Ep7w3pLSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = [1,2,3]\n",
        "print(sum(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR8ABRzVpRKw",
        "outputId": "420e44aa-9b03-4631-8582-629ee4f2aeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No 1 + 2 + 3 explicitly.\n",
        "Pytorch abstracts Neural network stages."
      ],
      "metadata": {
        "id": "0eYfoKUepbBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/get-started/locally/"
      ],
      "metadata": {
        "id": "2HdkQWGSpgGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZgZr2LWc8hh",
        "outputId": "283b4a8a-ad76-4b5b-adb7-a17d34505c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "EtQtgQTLp4ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1]]\n",
        "x = torch.tensor(data)\n",
        "# (consists of shape, datatype, device)"
      ],
      "metadata": {
        "id": "msVEnJOLoqOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGYGZQN6qGzw",
        "outputId": "f09329f6-aa8a-4933-8bd9-b5191da8669b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape: {x.shape}\")\n",
        "print(f\"Datatype: {x.dtype}\")\n",
        "print(f\"Device: {x.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOMxlyUpqU8g",
        "outputId": "d166fc90-e7d6-4405-e945-8a7ab679bd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([1, 1])\n",
            "Datatype: torch.int64\n",
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to specify shapes?"
      ],
      "metadata": {
        "id": "PMkihoBh0G4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea-8kK_EyLrx",
        "outputId": "84144822-94f9-4744-8e6d-1a7df4290da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5926, 0.5129, 0.3170, 0.5632])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(2, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz0Gq_yr0Lsa",
        "outputId": "e83a049f-cdf5-425a-f2fd-bbc5f69bc4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3466, 0.3946, 0.1790],\n",
              "        [0.9502, 0.4292, 0.9533]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Array"
      ],
      "metadata": {
        "id": "Kah9rTQAZXKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor starting at 0, ending at 1.0 (inclusive), with a step of 0.1\n",
        "# range_0_1 = torch.arange(0, 1.0, 0.1)\n",
        "range_0_1 = torch.arange(0, 1.0 + 0.0001, 0.1)\n",
        "# Note: Adding a small epsilon (e.g., 0.0001) to the stop value is a common practice\n",
        "# with floating-point steps to ensure the final value (1.0) is included due to\n",
        "# potential floating-point arithmetic inaccuracies.\n",
        "\n",
        "print(range_0_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3XaCohgtJK8",
        "outputId": "4e8427cd-387b-4031-861a-73682c0a57d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
            "        0.9000, 1.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_0_1 = torch.arange(0, 1.1, 0.1)\n",
        "range_0_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6LY2MvrtOol",
        "outputId": "8fc14242-74a9-4a31-da24-e97e01fc6a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
              "        0.9000, 1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We know how to index in python list\n",
        "i = [0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,0.9000, 1.0000]\n",
        "print(i[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQeYWTngazq6",
        "outputId": "24f6c15d-4295-4338-88fb-948dc536770b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the possible values as a PyTorch tensor\n",
        "possible_values = torch.arange(0.0, 1.1, 0.1)\n",
        "\n",
        "# Generate a single random integer index from 0 up to (but not including) the size of the tensor\n",
        "random_index = torch.randint(low=0, high=possible_values.size(0), size=(1,1))\n",
        "\n",
        "# # Select the value at the random index and extract the float number\n",
        "# random_float = possible_values[random_index]\n",
        "random_float = possible_values[random_index].item()\n",
        "\n",
        "# Print the result\n",
        "print(random_float)\n",
        "\n",
        "# # Use f-string formatting to print with 1 decimal place\n",
        "# print(f\"{random_float:.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYBjmMLm1caO",
        "outputId": "0e8b4ed7-b6d8-4ce7-d7df-963046b1327a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30000001192092896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7QCDbdFUG7zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\frac{\\partial L}{\\partial w}$ &nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;&nbsp; loss.backward()"
      ],
      "metadata": {
        "id": "AAJ6FJzHB33O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\frac{\\partial L}{\\partial w}$ &nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;&nbsp;&nbsp; W.grad"
      ],
      "metadata": {
        "id": "_Wd4prv2AK68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "W = W - (learning_rate * W.grad) &nbsp;&nbsp;&nbsp; :&nbsp;&nbsp;&nbsp; optimizer.step()"
      ],
      "metadata": {
        "id": "BYonLGvyAlF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Define Data and Hyperparameters ---\n",
        "x_data = torch.tensor([[1.0]])\n",
        "y_true = torch.tensor([[1.0]])\n",
        "# --- Model Parameter (W) ---\n",
        "W = torch.tensor([[0.2]], requires_grad=True)\n",
        "# --- Hyperparameters\n",
        "learning_rate = 0.1\n",
        "num_epochs = 200\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    ### STEP 1: Forward Pass (Calculate Prediction) ###\n",
        "    y_pred = W @ x_data\n",
        "\n",
        "    ### STEP 2: Calculate Loss ###\n",
        "    loss = y_true - y_pred\n",
        "\n",
        "    ### STEP 3: Backward Pass (Calculate Gradients) ###\n",
        "    loss.backward()\n",
        "\n",
        "    ### STEP 4: Update Parameters (The Manual Gradient Descent Step) ###\n",
        "    with torch.no_grad():\n",
        "        # W = W - (learning_rate * W.grad)\n",
        "        W -= (learning_rate * W.grad)\n",
        "\n",
        "    ### STEP 5: Reset means Zero the Gradients for the next iteration###\n",
        "    W.grad.zero_()\n",
        "\n",
        "    # --- Print and Break Condition ---\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}, Current W: {W.item():.4f}\")\n",
        "\n",
        "    # Break condition requested by the user\n",
        "    if loss.item() < 0.1:\n",
        "        print(f\"\\nBreak condition met: Loss ({loss.item():.6f}) < 0.1\")\n",
        "        break\n",
        "\n",
        "print(\"---------------------------------------\")\n",
        "print(f\"Final optimized weight (W): {W.item():.4f}\")\n",
        "print(f\"Target W should be 1.0.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZqnoH0NMQ5B",
        "outputId": "39a381c4-4d5d-4c45-82b2-d193cb41134c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/200], Loss: 0.800000, Current W: 0.3000\n",
            "Epoch [2/200], Loss: 0.700000, Current W: 0.4000\n",
            "Epoch [3/200], Loss: 0.600000, Current W: 0.5000\n",
            "Epoch [4/200], Loss: 0.500000, Current W: 0.6000\n",
            "Epoch [5/200], Loss: 0.400000, Current W: 0.7000\n",
            "Epoch [6/200], Loss: 0.300000, Current W: 0.8000\n",
            "Epoch [7/200], Loss: 0.200000, Current W: 0.9000\n",
            "Epoch [8/200], Loss: 0.100000, Current W: 1.0000\n",
            "\n",
            "Break condition met: Loss (0.100000) < 0.1\n",
            "---------------------------------------\n",
            "Final optimized weight (W): 1.0000\n",
            "Target W should be 1.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With Comments\n",
        "# --- 1. Define Data and Hyperparameters ---\n",
        "x_data = torch.tensor([[1.0]])\n",
        "y_true = torch.tensor([[1.0]])\n",
        "learning_rate = 0.1\n",
        "num_epochs = 200\n",
        "\n",
        "# --- 2. Initialize Model Parameter (W) ---\n",
        "# Start W at 0.2\n",
        "W = torch.tensor([[0.2]], requires_grad=True)\n",
        "\n",
        "print(f\"Starting value of W: {W.item():.4f}\")\n",
        "print(\"---------------------------------------\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    ### STEP 1: Forward Pass (Calculate Prediction) ###\n",
        "    y_pred = W * x_data\n",
        "\n",
        "    ### STEP 2: Calculate Loss ###\n",
        "    # Loss = y_true - y_pred. This loss tries to drive W to infinity.\n",
        "    loss = y_true - y_pred\n",
        "\n",
        "    ### STEP 3: Backward Pass (Calculate Gradients) ###\n",
        "    loss.backward()\n",
        "\n",
        "    ### STEP 4: Update Parameters (The Manual Gradient Descent Step) ###\n",
        "    # We wrap this in no_grad() because this is not part of the model's computation\n",
        "    with torch.no_grad():\n",
        "        # Update W in-place using W.data.sub_() to maintain the computation graph\n",
        "        # W = W - (learning_rate * W.grad)\n",
        "        W.data.sub_(learning_rate * W.grad)\n",
        "\n",
        "    ### STEP 5: Zero the Gradients ###\n",
        "    # We must reset the gradients for the next iteration\n",
        "    W.grad.zero_()\n",
        "\n",
        "    # --- Print and Break Condition ---\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}, Current W: {W.item():.4f}\")\n",
        "    # if (epoch + 1) % 10 == 0 or loss.item() < 0.1:\n",
        "\n",
        "\n",
        "    # Break condition requested by the user\n",
        "    if loss.item() < 0.1:\n",
        "        print(f\"\\nBreak condition met: Loss ({loss.item():.6f}) < 0.1\")\n",
        "        break\n",
        "\n",
        "print(\"---------------------------------------\")\n",
        "print(f\"Final optimized weight (W): {W.item():.4f}\")\n",
        "print(f\"Target W should be 1.0.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu8ik5OFHg_I",
        "outputId": "6afa6168-ac63-4ed9-f010-c5bdd496f332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting value of W: 0.2000\n",
            "---------------------------------------\n",
            "Epoch [1/200], Loss: 0.800000, Current W: 0.3000\n",
            "Epoch [2/200], Loss: 0.700000, Current W: 0.4000\n",
            "Epoch [3/200], Loss: 0.600000, Current W: 0.5000\n",
            "Epoch [4/200], Loss: 0.500000, Current W: 0.6000\n",
            "Epoch [5/200], Loss: 0.400000, Current W: 0.7000\n",
            "Epoch [6/200], Loss: 0.300000, Current W: 0.8000\n",
            "Epoch [7/200], Loss: 0.200000, Current W: 0.9000\n",
            "Epoch [8/200], Loss: 0.100000, Current W: 1.0000\n",
            "\n",
            "Break condition met: Loss (0.100000) < 0.1\n",
            "---------------------------------------\n",
            "Final optimized weight (W): 1.0000\n",
            "Target W should be 1.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Needed\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- 1. Define Data ---\n",
        "x_data = torch.tensor([[1.0]])\n",
        "true_W = torch.tensor([[1.0]])\n",
        "y_true = x_data @ true_W\n",
        "\n",
        "# --- 2. Initialize Model Parameters ---\n",
        "W = torch.tensor([[0.2]], requires_grad=True)\n",
        "\n",
        "y_pred = W @ x_data\n",
        "\n",
        "# --- 3. Define the Custom Loss Function and Optimizer ---\n",
        "# Custom Loss: Loss = y - predicted_y (y - w*x)\n",
        "loss = y_true - y_pred\n",
        "\n",
        "learning_rate = 0.1\n",
        "optimizer = optim.SGD([W], lr=learning_rate)\n",
        "\n",
        "# --- 4. Training Loop ---\n",
        "num_epochs = 100\n",
        "\n",
        "print(f\"Starting value of w: {W.item():.2f}\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # a. Forward Pass: Calculate the prediction\n",
        "    y_pred = W @ x_data\n",
        "\n",
        "    # b. Calculate Loss: Loss = y - w*x\n",
        "    loss = y_true - y_pred\n",
        "\n",
        "    # c. Zero Gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # d. Backward Pass: Calculate the gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # e. Update Weights\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.3f}, Current w: {w.item():.2f}\")\n",
        "\n",
        "   7\n",
        "\n",
        "    # # f. Print progress\n",
        "    # if (epoch + 1) % 10 == 0:\n",
        "    #     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.6f}, Current w: {w.item():.4f}\")\n",
        "\n",
        "# --- 5. Final Result ---\n",
        "print(f\"The final weight (w) is: {W.item():.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAvNzxKt5mhD",
        "outputId": "eb3eee55-15b6-4e92-d84c-6d4714694648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting value of w: 0.20\n",
            "Epoch [1/100], Loss: 0.800, Current w: 1.00\n",
            "Epoch [2/100], Loss: 0.700, Current w: 1.00\n",
            "Epoch [3/100], Loss: 0.600, Current w: 1.00\n",
            "Epoch [4/100], Loss: 0.500, Current w: 1.00\n",
            "Epoch [5/100], Loss: 0.400, Current w: 1.00\n",
            "Epoch [6/100], Loss: 0.300, Current w: 1.00\n",
            "Epoch [7/100], Loss: 0.200, Current w: 1.00\n",
            "Epoch [8/100], Loss: 0.100, Current w: 1.00\n",
            "The final weight (w) is: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_t3DsUovESHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQ2FVc2A9Cn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using MSE loss\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# --- 1. Data Initialization ---\n",
        "# The target data is x=1, y=1.\n",
        "# The relationship is y = w * x, so the optimal w should be 1.0.\n",
        "X = torch.tensor([1.0])\n",
        "Y = torch.tensor([1.0])\n",
        "\n",
        "# --- 2. Model Parameter Initialization ---\n",
        "# Initialize the weight 'w' as a Tensor that requires gradients.\n",
        "# This makes 'w' a learnable parameter.\n",
        "w = torch.tensor([0.2], requires_grad=True)\n",
        "\n",
        "# --- 3. Optimizer and Loss Function ---\n",
        "# We use Stochastic Gradient Descent (SGD) to update 'w'.\n",
        "# The learning rate (lr) controls the step size of the update.\n",
        "learning_rate = 0.05\n",
        "optimizer = optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "# We must use a standard loss function like Mean Squared Error (MSE).\n",
        "# Note: The loss requested by the user (Loss = Y - Y_pred) is unsuitable for\n",
        "# minimization because minimizing L = 1 - w would drive w to infinity, not 1.\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "# --- 4. Training Loop ---\n",
        "num_epochs = 100\n",
        "\n",
        "print(f\"Initial W: {w.item():.4f}\")\n",
        "print(\"--- Training Started ---\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Zero the gradients from the previous iteration\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 1. Forward Pass: Calculate the prediction\n",
        "    # Predict Y (Y_pred) using the current W and input X\n",
        "    Y_pred = w * X\n",
        "\n",
        "    # 2. Calculate the Loss\n",
        "    loss = loss_function(Y_pred, Y)\n",
        "\n",
        "    # 3. Backward Pass: Calculate gradients (dLoss/dW)\n",
        "    loss.backward()\n",
        "\n",
        "    # 4. Update Weights: Adjust W using the calculated gradient\n",
        "    # w = w - lr * (dLoss/dW)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print status every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1:03}/{num_epochs}] | Loss: {loss.item():.6f} | Current W: {w.item():.4f}\")\n",
        "\n",
        "print(\"--- Training Finished ---\")\n",
        "print(f\"Target Y: {Y.item()}\")\n",
        "print(f\"Final W: {w.item():.4f}\")\n",
        "print(f\"Final Predicted Y: {(w * X).item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BuY7voY1chz",
        "outputId": "12a7adc9-2261-4c77-bf78-3f5a9cf97ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial W: 0.2000\n",
            "--- Training Started ---\n",
            "Epoch [010/100] | Loss: 0.096061 | Current W: 0.7211\n",
            "Epoch [020/100] | Loss: 0.011679 | Current W: 0.9027\n",
            "Epoch [030/100] | Loss: 0.001420 | Current W: 0.9661\n",
            "Epoch [040/100] | Loss: 0.000173 | Current W: 0.9882\n",
            "Epoch [050/100] | Loss: 0.000021 | Current W: 0.9959\n",
            "Epoch [060/100] | Loss: 0.000003 | Current W: 0.9986\n",
            "Epoch [070/100] | Loss: 0.000000 | Current W: 0.9995\n",
            "Epoch [080/100] | Loss: 0.000000 | Current W: 0.9998\n",
            "Epoch [090/100] | Loss: 0.000000 | Current W: 0.9999\n",
            "Epoch [100/100] | Loss: 0.000000 | Current W: 1.0000\n",
            "--- Training Finished ---\n",
            "Target Y: 1.0\n",
            "Final W: 1.0000\n",
            "Final Predicted Y: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AG8l5NgprmQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5XPV4UlpgTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJ_g3BMVpgfo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}